{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tNoh4sG6o07f"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import tensorflow as tf \n",
        "from keras.datasets import mnist \n",
        "from keras.layers import Input, Dense, Reshape, Flatten\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSwWmVl7plmX",
        "outputId": "1dd1958d-4d9c-4d8f-cc45-4b29bacd90c0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7u4tbVMFp8LZ",
        "outputId": "fcd36276-5273-47d2-8aea-e4de8b98090b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows = 28\n",
        "img_cols = 28\n",
        "channels = 1\n",
        "img_shape = (img_rows, img_cols, channels)"
      ],
      "metadata": {
        "id": "Mfcb29wMru_I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "\n",
        "    noise_shape = (100,)   \n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(256, input_shape=noise_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    \n",
        "    model.add(Dense(np.prod(img_shape), activation='tanh'))\n",
        "    model.add(Reshape(img_shape))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    noise = Input(shape=noise_shape)\n",
        "    img = model(noise)  \n",
        "\n",
        "    return Model(noise, img)"
      ],
      "metadata": {
        "id": "j0qwnAOOuyZ8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Flatten(input_shape=img_shape))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.summary()\n",
        "\n",
        "    img = Input(shape=img_shape)\n",
        "    validity = model(img)\n",
        "\n",
        "    return Model(img, validity)"
      ],
      "metadata": {
        "id": "pNShMxuacbM7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs, batch_size=128, save_interval=50):\n",
        "\n",
        "    (X_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "\n",
        "    X_train = np.expand_dims(X_train, axis=3) \n",
        "\n",
        "    half_batch = int(batch_size / 2)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "\n",
        "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
        "        imgs = X_train[idx]\n",
        "\n",
        " \n",
        "        noise = np.random.normal(0, 1, (half_batch, 100))\n",
        "\n",
        "\n",
        "        gen_imgs = generator.predict(noise)\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
        "        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
        "\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) \n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, 100)) \n",
        "\n",
        "        \n",
        "        valid_y = np.array([1] * batch_size) \n",
        "        g_loss = combined.train_on_batch(noise, valid_y)\n",
        "        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "\n",
        "        \n",
        "        if epoch % save_interval == 0:\n",
        "            save_imgs(epoch)\n"
      ],
      "metadata": {
        "id": "d7NURLtrdx2P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_imgs(epoch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, 100))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(\"/content/images/mnist_%d.png\" % epoch)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "xGvlLmYBd0yZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir images"
      ],
      "metadata": {
        "id": "ATVk_iSQodmZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer = Adam(0.0002, 0.5)  \n",
        "\n",
        "discriminator=build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "\n",
        "generator =build_generator()\n",
        "generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        " \n",
        "z = Input(shape=(100,))   #Our random input to the generator\n",
        "img = generator(z)\n",
        " \n",
        "discriminator.trainable = False  #discriminator cannot be trained while generator is being trained\n",
        "\n",
        "  \n",
        "valid = discriminator(img)  #Validity check on the generated image\n",
        "\n",
        "\n",
        "\n",
        "combined = Model(z, valid)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "train(epochs=100, batch_size=32, save_interval=10)\n",
        "\n",
        "\n",
        "\n",
        "generator.save('generator_model.h5')  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKAZnrsvkqeR",
        "outputId": "161b6f61-e7e9-424d-88a7-b6f87b18d931"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               401920    \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 533,505\n",
            "Trainable params: 533,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 256)               25856     \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1024)              525312    \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 784)               803600    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,493,520\n",
            "Trainable params: 1,489,936\n",
            "Non-trainable params: 3,584\n",
            "_________________________________________________________________\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "0 [D loss: 0.644370, acc.: 43.75%] [G loss: 0.718378]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1 [D loss: 0.374002, acc.: 87.50%] [G loss: 0.666885]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "2 [D loss: 0.331921, acc.: 87.50%] [G loss: 0.740994]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3 [D loss: 0.329043, acc.: 81.25%] [G loss: 0.875040]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "4 [D loss: 0.298820, acc.: 90.62%] [G loss: 0.913530]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "5 [D loss: 0.265442, acc.: 93.75%] [G loss: 1.124575]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "6 [D loss: 0.248733, acc.: 96.88%] [G loss: 1.250138]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "7 [D loss: 0.218789, acc.: 96.88%] [G loss: 1.502508]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "8 [D loss: 0.153976, acc.: 100.00%] [G loss: 1.679430]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "9 [D loss: 0.146087, acc.: 100.00%] [G loss: 1.832827]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "10 [D loss: 0.135234, acc.: 100.00%] [G loss: 2.082011]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "11 [D loss: 0.090538, acc.: 100.00%] [G loss: 2.104275]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "12 [D loss: 0.079455, acc.: 100.00%] [G loss: 2.221200]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "13 [D loss: 0.072949, acc.: 100.00%] [G loss: 2.335509]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "14 [D loss: 0.072699, acc.: 100.00%] [G loss: 2.447072]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "15 [D loss: 0.070585, acc.: 100.00%] [G loss: 2.582136]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "16 [D loss: 0.051794, acc.: 100.00%] [G loss: 2.505344]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "17 [D loss: 0.058716, acc.: 100.00%] [G loss: 2.743045]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "18 [D loss: 0.056653, acc.: 100.00%] [G loss: 2.744597]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "19 [D loss: 0.050926, acc.: 100.00%] [G loss: 2.904091]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "20 [D loss: 0.032622, acc.: 100.00%] [G loss: 2.905478]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "21 [D loss: 0.039904, acc.: 100.00%] [G loss: 2.991111]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "22 [D loss: 0.036992, acc.: 100.00%] [G loss: 3.102402]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "23 [D loss: 0.032717, acc.: 100.00%] [G loss: 3.134874]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "24 [D loss: 0.030341, acc.: 100.00%] [G loss: 3.267857]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "25 [D loss: 0.021063, acc.: 100.00%] [G loss: 3.254028]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "26 [D loss: 0.024376, acc.: 100.00%] [G loss: 3.301379]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "27 [D loss: 0.021441, acc.: 100.00%] [G loss: 3.246970]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "28 [D loss: 0.026993, acc.: 100.00%] [G loss: 3.217850]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "29 [D loss: 0.026061, acc.: 100.00%] [G loss: 3.313284]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "30 [D loss: 0.032103, acc.: 100.00%] [G loss: 3.359912]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "31 [D loss: 0.025513, acc.: 100.00%] [G loss: 3.362649]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "32 [D loss: 0.032728, acc.: 100.00%] [G loss: 3.555055]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "33 [D loss: 0.016416, acc.: 100.00%] [G loss: 3.572265]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "34 [D loss: 0.022887, acc.: 100.00%] [G loss: 3.579013]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "35 [D loss: 0.018875, acc.: 100.00%] [G loss: 3.608174]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "36 [D loss: 0.022785, acc.: 100.00%] [G loss: 3.633469]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "37 [D loss: 0.024443, acc.: 100.00%] [G loss: 3.611229]\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "38 [D loss: 0.018522, acc.: 100.00%] [G loss: 3.726580]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "39 [D loss: 0.021163, acc.: 100.00%] [G loss: 3.731882]\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "40 [D loss: 0.019165, acc.: 100.00%] [G loss: 3.815569]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "41 [D loss: 0.011263, acc.: 100.00%] [G loss: 3.814936]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "42 [D loss: 0.016030, acc.: 100.00%] [G loss: 3.930332]\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "43 [D loss: 0.017059, acc.: 100.00%] [G loss: 3.840289]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "44 [D loss: 0.013617, acc.: 100.00%] [G loss: 3.969112]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "45 [D loss: 0.015676, acc.: 100.00%] [G loss: 3.803799]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "46 [D loss: 0.013099, acc.: 100.00%] [G loss: 3.871770]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "47 [D loss: 0.012713, acc.: 100.00%] [G loss: 3.861142]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "48 [D loss: 0.013268, acc.: 100.00%] [G loss: 3.994205]\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "49 [D loss: 0.011884, acc.: 100.00%] [G loss: 3.825999]\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "50 [D loss: 0.009039, acc.: 100.00%] [G loss: 3.822455]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "51 [D loss: 0.020978, acc.: 100.00%] [G loss: 3.761904]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "52 [D loss: 0.019759, acc.: 100.00%] [G loss: 4.026505]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "53 [D loss: 0.013833, acc.: 100.00%] [G loss: 4.076677]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "54 [D loss: 0.019380, acc.: 100.00%] [G loss: 4.014078]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "55 [D loss: 0.012647, acc.: 100.00%] [G loss: 4.099340]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "56 [D loss: 0.013089, acc.: 100.00%] [G loss: 3.973415]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "57 [D loss: 0.013063, acc.: 100.00%] [G loss: 4.182029]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "58 [D loss: 0.013564, acc.: 100.00%] [G loss: 4.127197]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "59 [D loss: 0.008579, acc.: 100.00%] [G loss: 4.146337]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "60 [D loss: 0.013937, acc.: 100.00%] [G loss: 4.068952]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "61 [D loss: 0.011897, acc.: 100.00%] [G loss: 4.116531]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "62 [D loss: 0.009682, acc.: 100.00%] [G loss: 4.134981]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "63 [D loss: 0.016562, acc.: 100.00%] [G loss: 4.267133]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "64 [D loss: 0.010196, acc.: 100.00%] [G loss: 4.057355]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "65 [D loss: 0.008654, acc.: 100.00%] [G loss: 4.258996]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "66 [D loss: 0.026143, acc.: 100.00%] [G loss: 4.196027]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "67 [D loss: 0.010138, acc.: 100.00%] [G loss: 4.278818]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "68 [D loss: 0.015076, acc.: 100.00%] [G loss: 4.338644]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "69 [D loss: 0.016530, acc.: 100.00%] [G loss: 4.361437]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "70 [D loss: 0.010360, acc.: 100.00%] [G loss: 4.471152]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "71 [D loss: 0.012599, acc.: 100.00%] [G loss: 4.274485]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "72 [D loss: 0.009339, acc.: 100.00%] [G loss: 4.308973]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "73 [D loss: 0.013861, acc.: 100.00%] [G loss: 4.389830]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "74 [D loss: 0.013151, acc.: 100.00%] [G loss: 4.429761]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "75 [D loss: 0.013016, acc.: 100.00%] [G loss: 4.453763]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "76 [D loss: 0.012008, acc.: 100.00%] [G loss: 4.377852]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "77 [D loss: 0.015792, acc.: 100.00%] [G loss: 4.421001]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "78 [D loss: 0.016116, acc.: 100.00%] [G loss: 4.651573]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "79 [D loss: 0.013452, acc.: 100.00%] [G loss: 4.720159]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "80 [D loss: 0.014052, acc.: 100.00%] [G loss: 4.863872]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "81 [D loss: 0.012957, acc.: 100.00%] [G loss: 4.641750]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "82 [D loss: 0.012503, acc.: 100.00%] [G loss: 4.625397]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "83 [D loss: 0.011061, acc.: 100.00%] [G loss: 4.662928]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "84 [D loss: 0.005067, acc.: 100.00%] [G loss: 4.649620]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "85 [D loss: 0.008094, acc.: 100.00%] [G loss: 4.476206]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "86 [D loss: 0.008863, acc.: 100.00%] [G loss: 4.574072]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "87 [D loss: 0.013127, acc.: 100.00%] [G loss: 4.584081]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "88 [D loss: 0.009007, acc.: 100.00%] [G loss: 4.673201]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "89 [D loss: 0.007752, acc.: 100.00%] [G loss: 4.659254]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "90 [D loss: 0.012977, acc.: 100.00%] [G loss: 4.564455]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "91 [D loss: 0.006987, acc.: 100.00%] [G loss: 4.491864]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "92 [D loss: 0.020480, acc.: 100.00%] [G loss: 4.752282]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "93 [D loss: 0.004833, acc.: 100.00%] [G loss: 4.711360]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "94 [D loss: 0.008823, acc.: 100.00%] [G loss: 4.761049]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "95 [D loss: 0.008274, acc.: 100.00%] [G loss: 4.540366]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "96 [D loss: 0.007588, acc.: 100.00%] [G loss: 4.757530]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "97 [D loss: 0.022228, acc.: 100.00%] [G loss: 4.715673]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "98 [D loss: 0.009484, acc.: 100.00%] [G loss: 4.867748]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "99 [D loss: 0.016122, acc.: 100.00%] [G loss: 4.771417]\n"
          ]
        }
      ]
    }
  ]
}